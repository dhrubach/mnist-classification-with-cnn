{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/mnist-original/mnist-original.mat\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import warnings\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "tf.set_random_seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = loadmat('../input/mnist-original/mnist-original.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = mnist['data'].T\n",
    "y = mnist['label'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST data shape - (70000, 784)\n",
      "MNIST label shape - (70000,)\n"
     ]
    }
   ],
   "source": [
    "print('MNIST data shape - {0}'.format(x.shape))\n",
    "print('MNIST label shape - {0}'.format(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 28\n",
    "img_width = 28\n",
    "channels = 1\n",
    "\n",
    "input_shape = (img_height, img_width, channels)\n",
    "num_classes = 10\n",
    "\n",
    "epoch = 20\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform input image array into a compatible shape : (total images, image height, image width, number of channels)\n",
    "\n",
    "* spatial dimension of each image : 28 X 28\n",
    "* number of channels : 1 (gray scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x_reshape = x.reshape(x.shape[0], img_height, img_width, channels)\n",
    "\n",
    "print(x_reshape.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert output labels into one-hot encoded vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 10)\n"
     ]
    }
   ],
   "source": [
    "y_encoded = keras.utils.to_categorical(y, num_classes)\n",
    "\n",
    "print(y_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display one-hot encoded 'label' vectors of 10 random images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = rn.sample(range(0, len(y_encoded)), 10)\n",
    "y_random = []\n",
    "for i in idx:\n",
    "    y_random.append([int(x) for x in y_encoded[i]])\n",
    "\n",
    "y_random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* each pixel value should be *float* type\n",
    "* since all are *gray scale* images, normalize by dividing with 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_reshape = x_reshape.astype('float32')\n",
    "x_reshape /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_reshape, y_encoded, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape : image - (52500, 28, 28, 1), label - (52500, 10)\n",
      "test data shape : image - (17500, 28, 28, 1), label - (17500, 10)\n"
     ]
    }
   ],
   "source": [
    "print('training data shape : image - {0}, label - {1}'.format(x_train.shape, y_train.shape))\n",
    "print('test data shape : image - {0}, label - {1}'.format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display a random image from training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd450426c88>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "idx = rn.randint(0, x_train.shape[0])\n",
    "plt.imshow(x_train[idx][:,:,0],\"gray\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split training dataset further into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape : image - (39375, 28, 28, 1), label - (39375, 10)\n",
      "validation data shape : image - (13125, 28, 28, 1), label - (13125, 10)\n"
     ]
    }
   ],
   "source": [
    "print('training data shape : image - {0}, label - {1}'.format(x_train.shape, y_train.shape))\n",
    "print('validation data shape : image - {0}, label - {1}'.format(x_validation.shape, y_validation.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "model = Sequential()\n",
    "\n",
    "# first conv layer\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "\n",
    "# second conv layer\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# flatten and put a fully connected layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu')) # fully connected\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# softmax layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39375 samples, validate on 13125 samples\n",
      "Epoch 1/20\n",
      "39375/39375 [==============================] - 6s 149us/step - loss: 0.3394 - accuracy: 0.8936 - val_loss: 0.0947 - val_accuracy: 0.9708\n",
      "Epoch 2/20\n",
      "39375/39375 [==============================] - 2s 60us/step - loss: 0.1132 - accuracy: 0.9658 - val_loss: 0.0676 - val_accuracy: 0.9789\n",
      "Epoch 3/20\n",
      "39375/39375 [==============================] - 2s 61us/step - loss: 0.0811 - accuracy: 0.9758 - val_loss: 0.0553 - val_accuracy: 0.9829\n",
      "Epoch 4/20\n",
      "39375/39375 [==============================] - 2s 61us/step - loss: 0.0654 - accuracy: 0.9801 - val_loss: 0.0521 - val_accuracy: 0.9836\n",
      "Epoch 5/20\n",
      "39375/39375 [==============================] - 2s 60us/step - loss: 0.0543 - accuracy: 0.9837 - val_loss: 0.0458 - val_accuracy: 0.9867\n",
      "Epoch 6/20\n",
      "39375/39375 [==============================] - 2s 61us/step - loss: 0.0490 - accuracy: 0.9851 - val_loss: 0.0557 - val_accuracy: 0.9841\n",
      "Epoch 7/20\n",
      "39375/39375 [==============================] - 2s 60us/step - loss: 0.0411 - accuracy: 0.9875 - val_loss: 0.0473 - val_accuracy: 0.9869\n",
      "Epoch 8/20\n",
      "39375/39375 [==============================] - 2s 60us/step - loss: 0.0393 - accuracy: 0.9881 - val_loss: 0.0480 - val_accuracy: 0.9873\n",
      "Epoch 9/20\n",
      "39375/39375 [==============================] - 2s 61us/step - loss: 0.0350 - accuracy: 0.9889 - val_loss: 0.0498 - val_accuracy: 0.9864\n",
      "Epoch 10/20\n",
      "39375/39375 [==============================] - 2s 60us/step - loss: 0.0334 - accuracy: 0.9892 - val_loss: 0.0415 - val_accuracy: 0.9878\n",
      "Epoch 11/20\n",
      "39375/39375 [==============================] - 2s 60us/step - loss: 0.0293 - accuracy: 0.9907 - val_loss: 0.0454 - val_accuracy: 0.9881\n",
      "Epoch 12/20\n",
      "39375/39375 [==============================] - 2s 60us/step - loss: 0.0272 - accuracy: 0.9916 - val_loss: 0.0419 - val_accuracy: 0.9882\n",
      "Epoch 13/20\n",
      "39375/39375 [==============================] - 2s 61us/step - loss: 0.0283 - accuracy: 0.9915 - val_loss: 0.0409 - val_accuracy: 0.9895\n",
      "Epoch 14/20\n",
      "39375/39375 [==============================] - 2s 60us/step - loss: 0.0248 - accuracy: 0.9925 - val_loss: 0.0461 - val_accuracy: 0.9875\n",
      "Epoch 15/20\n",
      "39375/39375 [==============================] - 2s 60us/step - loss: 0.0237 - accuracy: 0.9925 - val_loss: 0.0445 - val_accuracy: 0.9893\n",
      "Epoch 16/20\n",
      "39375/39375 [==============================] - 2s 61us/step - loss: 0.0208 - accuracy: 0.9935 - val_loss: 0.0457 - val_accuracy: 0.9890\n",
      "Epoch 17/20\n",
      "39375/39375 [==============================] - 2s 60us/step - loss: 0.0202 - accuracy: 0.9935 - val_loss: 0.0482 - val_accuracy: 0.9885\n",
      "Epoch 18/20\n",
      "39375/39375 [==============================] - 2s 61us/step - loss: 0.0192 - accuracy: 0.9943 - val_loss: 0.0446 - val_accuracy: 0.9896\n",
      "Epoch 19/20\n",
      "39375/39375 [==============================] - 2s 60us/step - loss: 0.0197 - accuracy: 0.9935 - val_loss: 0.0440 - val_accuracy: 0.9888\n",
      "Epoch 20/20\n",
      "39375/39375 [==============================] - 2s 61us/step - loss: 0.0193 - accuracy: 0.9940 - val_loss: 0.0450 - val_accuracy: 0.9891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fd45027b710>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, \n",
    "         y_train,\n",
    "         batch_size = batch_size,\n",
    "         epochs = epoch,\n",
    "         verbose = 1,\n",
    "         validation_data=(x_validation, y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17500/17500 [==============================] - 1s 64us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0384097837367095, 0.9890857338905334]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'accuracy']\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Change Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(lr=0.0001, momentum=0.9, nesterov=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Model Training & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39375 samples, validate on 13125 samples\n",
      "Epoch 1/20\n",
      "39375/39375 [==============================] - 2s 61us/step - loss: 0.0171 - accuracy: 0.9946 - val_loss: 0.0448 - val_accuracy: 0.9895\n",
      "Epoch 2/20\n",
      "39375/39375 [==============================] - 2s 55us/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 0.0446 - val_accuracy: 0.9896\n",
      "Epoch 3/20\n",
      "39375/39375 [==============================] - 2s 56us/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.0448 - val_accuracy: 0.9895\n",
      "Epoch 4/20\n",
      "39375/39375 [==============================] - 2s 56us/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.0448 - val_accuracy: 0.9897\n",
      "Epoch 5/20\n",
      "39375/39375 [==============================] - 2s 55us/step - loss: 0.0146 - accuracy: 0.9955 - val_loss: 0.0447 - val_accuracy: 0.9896\n",
      "Epoch 6/20\n",
      "39375/39375 [==============================] - 2s 56us/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.0448 - val_accuracy: 0.9896\n",
      "Epoch 7/20\n",
      "39375/39375 [==============================] - 2s 56us/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 0.0450 - val_accuracy: 0.9899\n",
      "Epoch 8/20\n",
      "39375/39375 [==============================] - 2s 56us/step - loss: 0.0132 - accuracy: 0.9955 - val_loss: 0.0448 - val_accuracy: 0.9899\n",
      "Epoch 9/20\n",
      "39375/39375 [==============================] - 2s 55us/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 0.0449 - val_accuracy: 0.9899\n",
      "Epoch 10/20\n",
      "39375/39375 [==============================] - 2s 55us/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.0450 - val_accuracy: 0.9899\n",
      "Epoch 11/20\n",
      "39375/39375 [==============================] - 2s 56us/step - loss: 0.0130 - accuracy: 0.9955 - val_loss: 0.0449 - val_accuracy: 0.9899\n",
      "Epoch 12/20\n",
      "39375/39375 [==============================] - 2s 55us/step - loss: 0.0141 - accuracy: 0.9950 - val_loss: 0.0447 - val_accuracy: 0.9899\n",
      "Epoch 13/20\n",
      "39375/39375 [==============================] - 2s 55us/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.0448 - val_accuracy: 0.9899\n",
      "Epoch 14/20\n",
      "39375/39375 [==============================] - 2s 56us/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.0447 - val_accuracy: 0.9900\n",
      "Epoch 15/20\n",
      "39375/39375 [==============================] - 2s 56us/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.0446 - val_accuracy: 0.9901\n",
      "Epoch 16/20\n",
      "39375/39375 [==============================] - 2s 56us/step - loss: 0.0126 - accuracy: 0.9960 - val_loss: 0.0447 - val_accuracy: 0.9900\n",
      "Epoch 17/20\n",
      "39375/39375 [==============================] - 2s 56us/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 0.0447 - val_accuracy: 0.9899\n",
      "Epoch 18/20\n",
      "39375/39375 [==============================] - 2s 57us/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.0446 - val_accuracy: 0.9900\n",
      "Epoch 19/20\n",
      "39375/39375 [==============================] - 2s 56us/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 0.0446 - val_accuracy: 0.9899\n",
      "Epoch 20/20\n",
      "39375/39375 [==============================] - 2s 56us/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 0.0447 - val_accuracy: 0.9899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fd43edeef98>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, \n",
    "         y_train,\n",
    "         batch_size = batch_size,\n",
    "         epochs = epoch,\n",
    "         verbose = 1,\n",
    "         validation_data=(x_validation, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17500/17500 [==============================] - 1s 63us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03753949086698745, 0.9904000163078308]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *marginal improvement on change of optimizer from Adadelta to SGD*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
